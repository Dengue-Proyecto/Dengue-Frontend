<div class="container">
  <h1 class="text-center">RESULTADOS DE LA EVALUACIÓN</h1>
  <h2 class="text-center">Comparativa de Modelos</h2>

  <!-- Tabla de Resultados por Modelo -->
  <table class="table table-bordered table-striped">
    <thead>
    <tr>
      <th>Modelo</th>
      <th>Riesgo de Dengue</th>
      <th>Probabilidad</th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>Máquinas de Vectores de Soporte (SVM Lineal)</td>
      <td>{{ riesgo_lineal }}</td>
      <td>{{ probabilidad_lineal_pct }}%</td>
    </tr>
    <tr>
      <td>Máquinas de Vectores de Soporte (SVM Polinómico)</td>
      <td>{{ riesgo_poli }}</td>
      <td>{{ probabilidad_poli_pct }}%</td>
    </tr>
    <tr>
      <td>Máquinas de Vectores de Soporte (SVM RBF)</td>
      <td>{{ riesgo_rbf }}</td>
      <td>{{ probabilidad_rbf_pct }}%</td>
    </tr>
    <tr>
      <td>Máquinas de Vectores de Soporte (SVM Sigmoid)</td>
      <td>{{ riesgo_sigmoid }}</td>
      <td>{{ probabilidad_sigmoid_pct }}%</td>
    </tr>
    <tr>
      <td>Bosque Aleatorio (Random Forest)</td>
      <td>{{ riesgo_random_forest }}</td>
      <td>{{ probabilidad_random_forest_pct }}%</td>
    </tr>
    <tr>
      <td>XGboost (Extreme Gradient Boosting)</td>
      <td>{{ riesgo_xgboost }}</td>
      <td>{{ probabilidad_xgboost_pct }}%</td>
    </tr>
    </tbody>
  </table>

  <!-- Métricas por modelo -->
  <h2 class="text-center mt-4">Métricas por Modelo</h2>

  <div class="metrics-grid">
    <div *ngFor="let modelo of metricas | keyvalue" class="metric-card model-metric-card">
      <h4 class="text-capitalize">{{ nombreModelos[modelo.key] || modelo.key }}</h4>
      <ul>
        <li><strong>Precisión:</strong> {{ modelo.value?.accuracy | number:'1.2-2' }}%</li>
        <li><strong>AUC-ROC:</strong> {{ modelo.value?.auc_roc | number:'1.2-2' }}%</li>
        <li><strong>Porcentaje de verdaderos positivos:</strong> {{ modelo.value?.recall | number:'1.2-2' }}%</li>
        <li><strong>Especificidad:</strong> {{ modelo.value?.specificity | number:'1.2-2' }}%</li>
        <li><strong>Porcentaje de falsos positivos:</strong> {{ modelo.value?.fpr | number:'1.2-2' }}%</li>
        <li><strong>Puntuacion F1:</strong> {{ modelo.value?.f1_score | number:'1.2-2' }}%</li>
        <li><strong>Tiempo de Predicción Aproximado:</strong> {{ modelo.value?.prediction_time | number:'1.4-4' }} s</li>
      </ul>
    </div>
  </div>

  <!-- Métricas Generales -->
  <h3 class="text-center">Métricas Generales</h3>

  <div class="metrics-container">
    <div class="metric-card bg-primary">
      <h4>Precisión Promedio</h4>
      <p>{{ precision_promedio }}%</p>
    </div>
    <div class="metric-card bg-success">
      <h4>Recall Promedio</h4>
      <p>{{ recall_promedio }}%</p>
    </div>
    <div class="metric-card bg-danger">
      <h4>Tiempo Promedio de Inferencia</h4>
      <p>{{ tiempo_promedio }} s</p>
    </div>
  </div>

  <!-- Conclusión -->
  <div class="conclusion">
    <h3 class="text-center">Conclusión</h3>
    <p class="text-center">
      El modelo con mejor precisión es
      <strong>__</strong>
      con un __% de precisión
      y un nivel de riesgo de <strong>__</strong>.
    </p>
  </div>

  <div class="text-center mt-4">
    <a class="btn btn-secondary" routerLink="/form">Volver a evaluar</a>
  </div>

</div>
